{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_path = \"IsoDatasetPro/Chordlab\"\n",
    "wav_song_path = \"IsoDatasetPro/Songs/\"\n",
    "IsoDataset = \"IsoDataset/\"\n",
    "IsoDatasetPro = \"IsoDatasetPro/\"\n",
    "combined_path = \"IsoDatasetPro/CombinedData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories (merging 'X' into 'N')\n",
    "roots = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B', 'N', 'X']\n",
    "basses = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B', 'N', 'X']\n",
    "triads = ['Major', 'Minor', 'Diminished', 'Augmented', 'Sus2', 'Sus4', 'N', 'X']\n",
    "fourths = ['dim7', 'min7', 'maj7', 'maj6', '7', 'N', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample: 01_01.csv\n",
      "Processing sample: 01_02.csv\n",
      "Processing sample: 01_03.csv\n",
      "Processing sample: 01_04.csv\n",
      "Processing sample: 01_05.csv\n",
      "Processing sample: 01_06.csv\n",
      "Processing sample: 01_07.csv\n",
      "Processing sample: 01_08.csv\n",
      "Processing sample: 01_09.csv\n",
      "Processing sample: 01_10.csv\n",
      "Processing sample: 01_11.csv\n",
      "Processing sample: 01_12.csv\n",
      "Processing sample: 01_13.csv\n",
      "Processing sample: 01_14.csv\n",
      "Processing sample: 02_01.csv\n",
      "Processing sample: 02_02.csv\n",
      "Processing sample: 02_03.csv\n",
      "Processing sample: 02_04.csv\n",
      "Processing sample: 02_05.csv\n",
      "Processing sample: 02_06.csv\n",
      "Processing sample: 02_07.csv\n",
      "Processing sample: 02_08.csv\n",
      "Processing sample: 02_09.csv\n",
      "Processing sample: 02_10.csv\n",
      "Processing sample: 02_11.csv\n",
      "Processing sample: 02_12.csv\n",
      "Processing sample: 02_13.csv\n",
      "Processing sample: 02_14.csv\n",
      "Processing sample: 03_01.csv\n",
      "Processing sample: 03_02.csv\n",
      "Processing sample: 03_03.csv\n",
      "Processing sample: 03_04.csv\n",
      "Processing sample: 03_05.csv\n",
      "Processing sample: 03_06.csv\n",
      "Processing sample: 03_07.csv\n",
      "Processing sample: 03_08.csv\n",
      "Processing sample: 03_09.csv\n",
      "Processing sample: 03_10.csv\n",
      "Processing sample: 03_11.csv\n",
      "Processing sample: 03_12.csv\n",
      "Processing sample: 03_13.csv\n",
      "Processing sample: 04_01.csv\n",
      "Processing sample: 04_02.csv\n",
      "Processing sample: 04_03.csv\n",
      "Processing sample: 04_04.csv\n",
      "Processing sample: 04_05.csv\n",
      "Processing sample: 04_06.csv\n",
      "Processing sample: 04_07.csv\n",
      "Processing sample: 04_08.csv\n",
      "Processing sample: 04_09.csv\n",
      "Processing sample: 04_10.csv\n",
      "Processing sample: 04_11.csv\n",
      "Processing sample: 04_12.csv\n",
      "Processing sample: 04_13.csv\n",
      "Processing sample: 04_14.csv\n",
      "Processing sample: 05_01.csv\n",
      "Processing sample: 05_02.csv\n",
      "Processing sample: 05_03.csv\n",
      "Processing sample: 05_04.csv\n",
      "Processing sample: 05_05.csv\n",
      "Processing sample: 05_06.csv\n",
      "Processing sample: 05_07.csv\n",
      "Processing sample: 05_08.csv\n",
      "Processing sample: 05_09.csv\n",
      "Processing sample: 05_10.csv\n",
      "Processing sample: 05_11.csv\n",
      "Processing sample: 05_12.csv\n",
      "Processing sample: 05_13.csv\n",
      "Processing sample: 05_14.csv\n",
      "Processing sample: 06_01.csv\n",
      "Processing sample: 06_02.csv\n",
      "Processing sample: 06_03.csv\n",
      "Processing sample: 06_04.csv\n",
      "Processing sample: 06_05.csv\n",
      "Processing sample: 06_06.csv\n",
      "Processing sample: 06_07.csv\n",
      "Processing sample: 06_08.csv\n",
      "Processing sample: 06_09.csv\n",
      "Processing sample: 06_10.csv\n",
      "Processing sample: 06_11.csv\n",
      "Processing sample: 06_12.csv\n",
      "Processing sample: 06_13.csv\n",
      "Processing sample: 06_14.csv\n",
      "Processing sample: 07_01.csv\n",
      "Processing sample: 07_02.csv\n",
      "Processing sample: 07_03.csv\n",
      "Processing sample: 07_04.csv\n",
      "Processing sample: 07_05.csv\n",
      "Processing sample: 07_06.csv\n",
      "Processing sample: 07_07.csv\n",
      "Processing sample: 07_08.csv\n",
      "Processing sample: 07_09.csv\n",
      "Processing sample: 07_10.csv\n",
      "Processing sample: 07_11.csv\n",
      "Processing sample: 07_12.csv\n",
      "Processing sample: 07_13.csv\n",
      "Processing sample: 07_14.csv\n",
      "Processing sample: 08_01.csv\n",
      "Processing sample: 08_02.csv\n",
      "Processing sample: 08_03.csv\n",
      "Processing sample: 08_04.csv\n",
      "Processing sample: 08_05.csv\n",
      "Processing sample: 08_06.csv\n",
      "Processing sample: 08_07.csv\n",
      "Processing sample: 08_08.csv\n",
      "Processing sample: 08_09.csv\n",
      "Processing sample: 08_10.csv\n",
      "Processing sample: 08_11.csv\n",
      "Processing sample: 08_12.csv\n",
      "Processing sample: 08_13.csv\n",
      "Processing sample: 09_01.csv\n",
      "Processing sample: 09_02.csv\n",
      "Processing sample: 09_03.csv\n",
      "Processing sample: 09_04.csv\n",
      "Processing sample: 09_05.csv\n",
      "Processing sample: 09_06.csv\n",
      "Processing sample: 09_07.csv\n",
      "Processing sample: 09_08.csv\n",
      "Processing sample: 09_09.csv\n",
      "Processing sample: 09_10.csv\n",
      "Processing sample: 09_11.csv\n",
      "        Chord  Percentage  Chord_Count\n",
      "2           A   11.450692        93813\n",
      "8           G   10.317377        84528\n",
      "1           E   10.060932        82427\n",
      "11          D    8.505660        69685\n",
      "9           C    7.437646        60935\n",
      "..        ...         ...          ...\n",
      "136     G:(6)    0.002075           17\n",
      "135     G:(7)    0.001587           13\n",
      "120   A:min/6    0.001587           13\n",
      "54   C#:min/4    0.001343           11\n",
      "131     B:(1)    0.001221           10\n",
      "\n",
      "[294 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#chord Distriubtion file\n",
    "\n",
    "# Dictionary to store chord counts\n",
    "chord_counts = Counter()\n",
    "total_chords = 0\n",
    "\n",
    "# Loop through each sample folder\n",
    "for file in os.listdir(combined_path):\n",
    "    print(f\"Processing sample: {file}\")\n",
    "    \n",
    "    combined_file = os.path.join(combined_path, file)\n",
    "    \n",
    "    if os.path.exists(combined_file):\n",
    "        df = pd.read_csv(combined_file)\n",
    "    \n",
    "        # Count chords in this file\n",
    "        chord_counts.update(df['Chord_Label'])\n",
    "        total_chords += len(df['Chord_Label'])\n",
    "\n",
    "# Calculate percentages for unique chords\n",
    "chord_percentages = {chord: (count / total_chords) * 100 for chord, count in chord_counts.items()}\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "chord_distribution_df = pd.DataFrame(list(chord_percentages.items()), columns=['Chord', 'Percentage'])\n",
    "\n",
    "# Add chord counts to the DataFrame\n",
    "chord_distribution_df['Chord_Count'] = chord_distribution_df['Chord'].map(chord_counts)\n",
    "\n",
    "# Sort by percentage (descending)\n",
    "chord_distribution_df = chord_distribution_df.sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "# Display the chord distribution\n",
    "print(chord_distribution_df)\n",
    "\n",
    "# Optionally, save the distribution to a CSV file\n",
    "chord_distribution_df.to_csv('IsoDatasetPro/chord_distribution.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
